{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43332b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/openai/whisper.git\n",
    "# https://ffmpeg.org/download.html\n",
    "# git clone https://git.ffmpeg.org/ffmpeg.git ffmpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951670f",
   "metadata": {},
   "source": [
    "fazendo um resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6b50a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AudioSegment\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Baixar recursos necessários para o NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Especificar o caminho do executável ffmpeg\n",
    "AudioSegment.converter = r\"C:\\Users\\eduardo.pezzi\\OneDrive - VITIVINICOLA JOLIMONT LTDA - EPP\\Documentos\\dados\\gptnovoambiente\\ffmpeg-2024\\ffmpeg-2024-07-04-git-03175b587c-essentials_build\\bin\\ffmpeg.exe\"\n",
    "\n",
    "# Lista personalizada de stopwords\n",
    "custom_stopwords = set(stopwords.words('portuguese')).union({\"aqui\", \"outra\", \"mais\", \"menos\"})\n",
    "\n",
    "def transcricao_audio_local(audio_path):\n",
    "    # Converter o áudio para wav usando pydub\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    wav_path = \"converted_audio.wav\"\n",
    "    audio.export(wav_path, format=\"wav\")\n",
    "\n",
    "    # Carregar o modelo Whisper\n",
    "    model = whisper.load_model(\"base\")\n",
    "\n",
    "    # Realizar a transcrição\n",
    "    resultado = model.transcribe(wav_path)\n",
    "    \n",
    "    # Retornar o texto transcrito\n",
    "    return resultado[\"text\"]\n",
    "\n",
    "def formatar_em_paragrafos(texto):\n",
    "    # Dividir o texto em sentenças/parágrafos\n",
    "    sentencas = texto.split('. ')\n",
    "    paragrafos = '\\n\\n'.join(sentencas)\n",
    "    return paragrafos\n",
    "\n",
    "def analise_sentimento(texto):\n",
    "    blob = TextBlob(texto)\n",
    "    sentimento = blob.sentiment\n",
    "    return sentimento\n",
    "\n",
    "def extrair_principais_palavras(texto, num_palavras=10):\n",
    "    # Remover pontuação\n",
    "    texto_limpo = texto.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenizar palavras\n",
    "    palavras = nltk.word_tokenize(texto_limpo)\n",
    "    # Converter para minúsculas\n",
    "    palavras = [palavra.lower() for palavra in palavras]\n",
    "    # Remover stopwords\n",
    "    palavras_filtradas = [palavra for palavra in palavras if palavra not in custom_stopwords]\n",
    "    # Contar frequência das palavras\n",
    "    frequencia = Counter(palavras_filtradas)\n",
    "    # Obter as palavras mais comuns\n",
    "    palavras_comuns = frequencia.most_common(num_palavras)\n",
    "    return palavras_comuns, palavras_filtradas\n",
    "\n",
    "def criar_nuvem_palavras(palavras_filtradas):\n",
    "    # Gerar a nuvem de palavras\n",
    "    texto = ' '.join(palavras_filtradas)\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(texto)\n",
    "    \n",
    "    # Exibir a nuvem de palavras\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Exemplo de uso\n",
    "transcricao = transcricao_audio_local('teste.mp3')\n",
    "if transcricao:\n",
    "    texto_formatado = formatar_em_paragrafos(transcricao)\n",
    "    print(\"Texto Formatado:\\n\", texto_formatado)\n",
    "    \n",
    "    sentimento = analise_sentimento(transcricao)\n",
    "    print(\"\\nAnálise de Sentimento:\")\n",
    "    print(f\"Polaridade: {sentimento.polarity}, Subjetividade: {sentimento.subjectivity}\")\n",
    "    \n",
    "    palavras_comuns, palavras_filtradas = extrair_principais_palavras(transcricao)\n",
    "    print(\"\\nPrincipais Palavras:\")\n",
    "    for palavra, frequencia in palavras_comuns:\n",
    "        print(f\"{palavra}: {frequencia}\")\n",
    "    \n",
    "    criar_nuvem_palavras(palavras_filtradas)\n",
    "else:\n",
    "    print(\"A transcrição falhou.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_transcricao = pd.DataFrame([{'texto_formatado': transcricao}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
